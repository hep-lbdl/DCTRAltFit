{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers import Lambda, Dense, Input, Layer, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LambdaCallback, EarlyStopping\n",
    "import keras.backend as K\n",
    "import keras\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.utils import remap_pids\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize pT and center (y, phi)\n",
    "def normalize(x):\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    for x in X:\n",
    "        normalize(x)\n",
    "    \n",
    "    # Remap PIDs to unique values in range [0,1]\n",
    "    remap_pids(X, pid_i=3)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to downloaded data from Zenodo\n",
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(data_dir + '1D_alphaS_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['X']\n",
    "Y = dataset['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data(X)\n",
    "Y = to_categorical(Y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mult = []\n",
    "#More preprocessing: zipping data points with no particle with parameters\n",
    "\n",
    "index = 0\n",
    "for jet in X:\n",
    "    pTs = jet[:,0]\n",
    "    alphaS = jet[0][4]\n",
    "    multiplicity = np.sum(pTs!=0)\n",
    "    X_mult.append([multiplicity, alphaS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mult = np.array(X_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_mult, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a DCTR Model\n",
    "First, we need to train a DCTR model to provide us with a reweighting function to be used during fitting.\n",
    "This is taken directly from the first Gaussian Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((2,))\n",
    "hidden_layer_1 = Dense(50, activation='relu')(inputs)\n",
    "hidden_layer_2 = Dense(50, activation='relu')(hidden_layer_1)\n",
    "hidden_layer_3 = Dense(50, activation='relu')(hidden_layer_2)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(hidden_layer_3)\n",
    "\n",
    "dctr_model = Model(inputs = inputs, outputs = outputs)\n",
    "dctr_model.compile(loss='categorical_crossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DCTR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 1440000 samples, validate on 360000 samples\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "1440000/1440000 [==============================] - 4s 3us/step - loss: 0.6931 - val_loss: 0.6925\n",
      "Epoch 2/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6928 - val_loss: 0.6925\n",
      "Epoch 3/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6927 - val_loss: 0.6926\n",
      "Epoch 4/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6927 - val_loss: 0.6926\n",
      "Epoch 5/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6926 - val_loss: 0.6925\n",
      "Epoch 6/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6927 - val_loss: 0.6926\n",
      "Epoch 7/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6925 - val_loss: 0.6923\n",
      "Epoch 8/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6921 - val_loss: 0.6916\n",
      "Epoch 9/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6913 - val_loss: 0.6914\n",
      "Epoch 10/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6897 - val_loss: 0.6885\n",
      "Epoch 11/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6883 - val_loss: 0.6876\n",
      "Epoch 12/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6874 - val_loss: 0.6894\n",
      "Epoch 13/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6867 - val_loss: 0.6860\n",
      "Epoch 14/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6859 - val_loss: 0.6859\n",
      "Epoch 15/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6856 - val_loss: 0.6857\n",
      "Epoch 16/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6855 - val_loss: 0.6861\n",
      "Epoch 17/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6851 - val_loss: 0.6850\n",
      "Epoch 18/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6849 - val_loss: 0.6847\n",
      "Epoch 19/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6846 - val_loss: 0.6868\n",
      "Epoch 20/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6845 - val_loss: 0.6847\n",
      "Epoch 21/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6846 - val_loss: 0.6845\n",
      "Epoch 22/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6846 - val_loss: 0.6850\n",
      "Epoch 23/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6847 - val_loss: 0.6844\n",
      "Epoch 24/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6843 - val_loss: 0.6846\n",
      "Epoch 25/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6844 - val_loss: 0.6843\n",
      "Epoch 26/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6846 - val_loss: 0.6849\n",
      "Epoch 27/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6844 - val_loss: 0.6846\n",
      "Epoch 28/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6843 - val_loss: 0.6844\n",
      "Epoch 29/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6845 - val_loss: 0.6845\n",
      "Epoch 30/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6843 - val_loss: 0.6851\n",
      "Epoch 31/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6843 - val_loss: 0.6843\n",
      "Epoch 32/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6843 - val_loss: 0.6844\n",
      "Epoch 33/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6846 - val_loss: 0.6845\n",
      "Epoch 34/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6843 - val_loss: 0.6844\n",
      "Epoch 35/200\n",
      "1440000/1440000 [==============================] - 2s 2us/step - loss: 0.6844 - val_loss: 0.6844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5207909dd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(patience = 10,\n",
    "                              restore_best_weights=True)\n",
    "dctr_model.fit(X_train, Y_train, \n",
    "               epochs=200, batch_size = 10000, \n",
    "               validation_data = (X_val, Y_val), \n",
    "               verbose = 1, \n",
    "               callbacks = [earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dataset = np.load(data_dir + 'test1D_default.npz')\n",
    "unknown_dataset = np.load(data_dir + 'test1D_alphaS.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = default_dataset['multiplicity']\n",
    "X_1 = unknown_dataset['multiplicity']\n",
    "\n",
    "labels0 = np.zeros(len(X_0))\n",
    "labels1 = np.ones(len(X_1))\n",
    "\n",
    "xvals = np.concatenate([X_0,X_1])\n",
    "yvals = np.concatenate([labels0,labels1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xvals, yvals, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining reweighting functions\n",
    "\n",
    "$w(x_{T,i},\\theta)=((f(x_{T,i},\\theta)/(1-f(x_{T,i},\\theta)))$\n",
    "\n",
    "Takes observable from simulation ${\\bf \\theta_0}$ and weights it to observable from data (target) ${\\bf \\theta_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(d): #from NN (DCTR)\n",
    "    f = dctr_model(d)\n",
    "    weights = (f[:,1])/(f[:,0])\n",
    "    weights = K.expand_dims(weights, axis = 1)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 16,897\n",
      "Trainable params: 16,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myinputs = Input(shape=(1,), dtype = tf.float32)\n",
    "x = Dense(128, activation='relu')(myinputs)\n",
    "x2 = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x2)\n",
    "          \n",
    "model = Model(inputs=myinputs, outputs=predictions)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "def my_loss_wrapper(inputs,val=0):\n",
    "    x  = inputs\n",
    "    x = K.squeeze(x, axis = 1)\n",
    "    x = K.gather(x, np.arange(500))\n",
    "\n",
    "    theta = 0. #starting value\n",
    "    #theta0 = tf.constant(val, dtype= tf.float32)#target value\n",
    "    \n",
    "    #creating tensor with same shape as inputs, with val in every entry\n",
    "    theta0_stack = K.constant(val, dtype=tf.float32, shape = x.shape)\n",
    "    #combining and reshaping into correct format:\n",
    "    data = K.stack((x, theta0_stack), axis=-1) \n",
    "    \n",
    "    w = reweight(data) #NN reweight\n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        # Mean Squared Loss\n",
    "        t_loss = y_true*(y_true - y_pred)**2+(w)*(1.-y_true)*(y_true - y_pred)**2\n",
    "        # Categorical Cross-Entropy Loss\n",
    "        '''\n",
    "        #Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        \n",
    "        t_loss = -((y_true)*K.log(y_pred) +w*(1-y_true)*K.log(1-y_pred))\n",
    "        '''\n",
    "        return K.mean(t_loss)\n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing theta = : 0.1\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2335 - acc: 0.5604 - val_loss: 0.2319 - val_acc: 0.5641\n",
      "testing theta = : 0.10250000000000001\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2322 - acc: 0.5626 - val_loss: 0.2353 - val_acc: 0.5608\n",
      "testing theta = : 0.10500000000000001\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2323 - acc: 0.5627 - val_loss: 0.2319 - val_acc: 0.5647\n",
      "testing theta = : 0.1075\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2326 - acc: 0.5628 - val_loss: 0.2322 - val_acc: 0.5647\n",
      "testing theta = : 0.11\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2331 - acc: 0.5629 - val_loss: 0.2330 - val_acc: 0.5620\n",
      "testing theta = : 0.1125\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2338 - acc: 0.5631 - val_loss: 0.2338 - val_acc: 0.5620\n",
      "testing theta = : 0.115\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 11us/step - loss: 0.2347 - acc: 0.5633 - val_loss: 0.2346 - val_acc: 0.5620\n",
      "testing theta = : 0.11750000000000001\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2357 - acc: 0.5630 - val_loss: 0.2355 - val_acc: 0.5647\n",
      "testing theta = : 0.12\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2369 - acc: 0.5635 - val_loss: 0.2370 - val_acc: 0.5641\n",
      "testing theta = : 0.1225\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2382 - acc: 0.5637 - val_loss: 0.2380 - val_acc: 0.5647\n",
      "testing theta = : 0.125\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2397 - acc: 0.5637 - val_loss: 0.2398 - val_acc: 0.5620\n",
      "testing theta = : 0.1275\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2410 - acc: 0.5634 - val_loss: 0.2408 - val_acc: 0.5647\n",
      "testing theta = : 0.13\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2423 - acc: 0.5637 - val_loss: 0.2422 - val_acc: 0.5647\n",
      "testing theta = : 0.1325\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2436 - acc: 0.5631 - val_loss: 0.2435 - val_acc: 0.5647\n",
      "testing theta = : 0.135\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2448 - acc: 0.5633 - val_loss: 0.2447 - val_acc: 0.5647\n",
      "testing theta = : 0.1375\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2460 - acc: 0.5630 - val_loss: 0.2459 - val_acc: 0.5647\n",
      "testing theta = : 0.14\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2468 - acc: 0.5630 - val_loss: 0.2468 - val_acc: 0.5608\n",
      "testing theta = : 0.14250000000000002\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2476 - acc: 0.5629 - val_loss: 0.2477 - val_acc: 0.5647\n",
      "testing theta = : 0.145\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2481 - acc: 0.5630 - val_loss: 0.2481 - val_acc: 0.5641\n",
      "testing theta = : 0.1475\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2484 - acc: 0.5628 - val_loss: 0.2484 - val_acc: 0.5647\n",
      "testing theta = : 0.15\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2486 - acc: 0.5622 - val_loss: 0.2487 - val_acc: 0.5620\n",
      "testing theta = : 0.1525\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2489 - acc: 0.5612 - val_loss: 0.2489 - val_acc: 0.5620\n",
      "testing theta = : 0.155\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2491 - acc: 0.5541 - val_loss: 0.2491 - val_acc: 0.5386\n",
      "testing theta = : 0.1575\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2494 - acc: 0.5115 - val_loss: 0.2494 - val_acc: 0.5093\n",
      "testing theta = : 0.16\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2496 - acc: 0.4785 - val_loss: 0.2497 - val_acc: 0.4885\n",
      "testing theta = : 0.1625\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 13us/step - loss: 0.2499 - acc: 0.4545 - val_loss: 0.2500 - val_acc: 0.4606\n",
      "testing theta = : 0.16499999999999998\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 13us/step - loss: 0.2503 - acc: 0.4414 - val_loss: 0.2503 - val_acc: 0.4380\n",
      "testing theta = : 0.16749999999999998\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 13us/step - loss: 0.2503 - acc: 0.4377 - val_loss: 0.2503 - val_acc: 0.4361\n",
      "testing theta = : 0.16999999999999998\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 13us/step - loss: 0.2498 - acc: 0.4379 - val_loss: 0.2498 - val_acc: 0.4360\n",
      "testing theta = : 0.1725\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 13us/step - loss: 0.2488 - acc: 0.4393 - val_loss: 0.2489 - val_acc: 0.4359\n",
      "testing theta = : 0.175\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 13us/step - loss: 0.2475 - acc: 0.4403 - val_loss: 0.2476 - val_acc: 0.4392\n",
      "testing theta = : 0.1775\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 13us/step - loss: 0.2461 - acc: 0.4421 - val_loss: 0.2461 - val_acc: 0.4445\n",
      "testing theta = : 0.18\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 14us/step - loss: 0.2445 - acc: 0.4445 - val_loss: 0.2445 - val_acc: 0.4392\n",
      "[[0.23188243029846087], [0.2352650043947829], [0.23188740226129692], [0.2322375190506379], [0.23299608796834945], [0.2337804054386086], [0.23455271714263493], [0.23552788031597932], [0.2369845422026184], [0.2380387070443895], [0.23975383583042356], [0.24082793162100846], [0.24222262441284126], [0.2434965641465452], [0.24470655098557473], [0.24587522484362126], [0.2467876773658726], [0.24769012774030366], [0.24805810424188773], [0.24841315423448881], [0.24870152316159672], [0.24888137046661643], [0.24908545254005326], [0.2493962408353885], [0.24970010485086175], [0.24997024315926764], [0.25030700931118594], [0.25033574361768035], [0.2498323244932625], [0.2488730300300651], [0.24757071405649186], [0.246093275124828], [0.2445382605575853]]\n"
     ]
    }
   ],
   "source": [
    "thetas = np.linspace(0.10, 0.18, 33)\n",
    "lvals = []\n",
    "\n",
    "\n",
    "for theta in thetas:\n",
    "    print(\"testing theta = :\", theta)\n",
    "    model.compile(optimizer='adam', loss=my_loss_wrapper(myinputs,theta),metrics=['accuracy'])\n",
    "    model.fit(np.array(X_train), y_train, epochs=1, batch_size=500,validation_data=(np.array(X_test), y_test),verbose=1)\n",
    "    lvals+=[model.history.history['val_loss']]\n",
    "    print\n",
    "    pass\n",
    "print(lvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvals_orig= [[0.21545321300832762],\n",
    "             [0.21320670744818118],\n",
    "             [0.21427190159964893],\n",
    "             [0.21600884579949908],\n",
    "             [0.2180913633149531],\n",
    "             [0.2203975125422908],\n",
    "             [0.22277363829521668],\n",
    "             [0.2252077442386912],\n",
    "             [0.22762178098782898],\n",
    "             [0.22985038127129276],\n",
    "             [0.2319808946715461],\n",
    "             [0.23389454455011421],\n",
    "             [0.23567747064969605],\n",
    "             [0.23733307556766603],\n",
    "             [0.23912259595882562],\n",
    "             [0.2411479534374343],\n",
    "             [0.24305367945796913],\n",
    "             [0.24457945177952448],\n",
    "             [0.24594977470114826],\n",
    "             [0.24723519961246185],\n",
    "             [0.24829403785988688],\n",
    "             [0.24910752758797672],\n",
    "             [0.24965062933042645],\n",
    "             [0.24994903881516722],\n",
    "             [0.25001448064835535],\n",
    "             [0.2498855436945127],\n",
    "             [0.24953465532097552],\n",
    "             [0.24896939413415062],\n",
    "             [0.2482402424948911],\n",
    "             [0.24736307265443935],\n",
    "             [0.2463511453424063],\n",
    "             [0.24517832743003964],\n",
    "             [0.24393402135206593]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thetas,lvals, label = 'multiplicity only')\n",
    "plt.plot(thetas, lvals_orig, label = 'full phase space, orig DCTR')\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Fitting alphaS with only multiplicity vs. full phase space\")\n",
    "plt.vlines(0.160, ymin = np.min(lvals_orig), ymax = np.max(lvals_orig), label = 'Truth')\n",
    "plt.legend()\n",
    "#plt.savefig(\"Fitting alphaS with only multiplicity vs full phase space.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the $\\theta$ and $g$ optimization together with a minimax setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(\". theta fit = \",model_fit.layers[-1].get_weights()[-1]))\n",
    "theta_fit_init = 0.12\n",
    "fit_vals = [theta_fit_init]\n",
    "append_fit_value = LambdaCallback(on_epoch_end=lambda batch, logs: \n",
    "                                               fit_vals.append(model_fit.layers[-1].get_weights()[0]))\n",
    "\n",
    "callbacks = [print_weights, append_fit_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "lambda_7 (Lambda)            (None, 1)                 1         \n",
      "=================================================================\n",
      "Total params: 16,898\n",
      "Trainable params: 16,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch:  0\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2482 - acc: 0.5224 - val_loss: 0.2443 - val_acc: 0.5381\n",
      ". theta fit =  0.12\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: -0.2486 - acc: 0.5391 - val_loss: -0.2542 - val_acc: 0.5381\n",
      ". theta fit =  0.1697952\n",
      "Epoch:  1\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2510 - acc: 0.5334 - val_loss: 0.2493 - val_acc: 0.5361\n",
      ". theta fit =  0.1697952\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 8s 9us/step - loss: -0.2495 - acc: 0.5358 - val_loss: -0.2494 - val_acc: 0.5361\n",
      ". theta fit =  0.16746299\n",
      "Epoch:  2\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 8s 9us/step - loss: 0.2510 - acc: 0.5174 - val_loss: 0.2491 - val_acc: 0.5558\n",
      ". theta fit =  0.16746299\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 8s 9us/step - loss: -0.2491 - acc: 0.5572 - val_loss: -0.2491 - val_acc: 0.5558\n",
      ". theta fit =  0.16714235\n",
      "Epoch:  3\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2503 - acc: 0.5008 - val_loss: 0.2488 - val_acc: 0.4729\n",
      ". theta fit =  0.16714235\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 6s 6us/step - loss: -0.2489 - acc: 0.4717 - val_loss: -0.2489 - val_acc: 0.4729\n",
      ". theta fit =  0.16344452\n",
      "Epoch:  4\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2504 - acc: 0.4881 - val_loss: 0.2489 - val_acc: 0.4999\n",
      ". theta fit =  0.16344452\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 9us/step - loss: -0.2489 - acc: 0.5000 - val_loss: -0.2489 - val_acc: 0.4999\n",
      ". theta fit =  0.16620716\n",
      "Epoch:  5\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: 0.2501 - acc: 0.4827 - val_loss: 0.2487 - val_acc: 0.4363\n",
      ". theta fit =  0.16620716\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: -0.2488 - acc: 0.4350 - val_loss: -0.2488 - val_acc: 0.4363\n",
      ". theta fit =  0.15963574\n",
      "Epoch:  6\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2502 - acc: 0.4804 - val_loss: 0.2488 - val_acc: 0.4442\n",
      ". theta fit =  0.15963574\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: -0.2489 - acc: 0.4428 - val_loss: -0.2488 - val_acc: 0.4442\n",
      ". theta fit =  0.15891221\n",
      "Epoch:  7\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2500 - acc: 0.4819 - val_loss: 0.2487 - val_acc: 0.4398\n",
      ". theta fit =  0.15891221\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: -0.2488 - acc: 0.4397 - val_loss: -0.2488 - val_acc: 0.4398\n",
      ". theta fit =  0.16440424\n",
      "Epoch:  8\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2500 - acc: 0.4787 - val_loss: 0.2490 - val_acc: 0.4999\n",
      ". theta fit =  0.16440424\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 9s 10us/step - loss: -0.2490 - acc: 0.5000 - val_loss: -0.2490 - val_acc: 0.4999\n",
      ". theta fit =  0.16409923\n",
      "Epoch:  9\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 12us/step - loss: 0.2495 - acc: 0.4765 - val_loss: 0.2488 - val_acc: 0.4442\n",
      ". theta fit =  0.16409923\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: -0.2489 - acc: 0.4428 - val_loss: -0.2489 - val_acc: 0.4442\n",
      ". theta fit =  0.16073635\n",
      "Epoch:  10\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2497 - acc: 0.4786 - val_loss: 0.2488 - val_acc: 0.4574\n",
      ". theta fit =  0.16073635\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: -0.2488 - acc: 0.4579 - val_loss: -0.2488 - val_acc: 0.4574\n",
      ". theta fit =  0.16407213\n",
      "Epoch:  11\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2497 - acc: 0.4747 - val_loss: 0.2488 - val_acc: 0.4368\n",
      ". theta fit =  0.16407213\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: -0.2489 - acc: 0.4360 - val_loss: -0.2488 - val_acc: 0.4368\n",
      ". theta fit =  0.16029963\n",
      "Epoch:  12\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: 0.2495 - acc: 0.4777 - val_loss: 0.2488 - val_acc: 0.4363\n",
      ". theta fit =  0.16029963\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 10s 11us/step - loss: -0.2488 - acc: 0.4350 - val_loss: -0.2488 - val_acc: 0.4363\n",
      ". theta fit =  0.16308464\n",
      "Epoch:  13\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 12us/step - loss: 0.2495 - acc: 0.4776 - val_loss: 0.2489 - val_acc: 0.4522\n",
      ". theta fit =  0.16308464\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 6s 7us/step - loss: -0.2490 - acc: 0.4509 - val_loss: -0.2490 - val_acc: 0.4522\n",
      ". theta fit =  0.15667962\n",
      "Epoch:  14\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 14s 15us/step - loss: 0.2491 - acc: 0.4785 - val_loss: 0.2486 - val_acc: 0.4878\n",
      ". theta fit =  0.15667962\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 14us/step - loss: -0.2489 - acc: 0.4879 - val_loss: -0.2489 - val_acc: 0.4878\n",
      ". theta fit =  0.16545841\n",
      "Epoch:  15\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 13s 14us/step - loss: 0.2492 - acc: 0.4719 - val_loss: 0.2487 - val_acc: 0.4368\n",
      ". theta fit =  0.16545841\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 13us/step - loss: -0.2488 - acc: 0.4360 - val_loss: -0.2488 - val_acc: 0.4368\n",
      ". theta fit =  0.16007978\n",
      "Epoch:  16\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 14us/step - loss: 0.2490 - acc: 0.4628 - val_loss: 0.2488 - val_acc: 0.4574\n",
      ". theta fit =  0.16007978\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 13us/step - loss: -0.2489 - acc: 0.4579 - val_loss: -0.2488 - val_acc: 0.4574\n",
      ". theta fit =  0.16371326\n",
      "Epoch:  17\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 13s 14us/step - loss: 0.2493 - acc: 0.4738 - val_loss: 0.2488 - val_acc: 0.4442\n",
      ". theta fit =  0.16371326\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 13s 14us/step - loss: -0.2489 - acc: 0.4428 - val_loss: -0.2489 - val_acc: 0.4442\n",
      ". theta fit =  0.16011083\n",
      "Epoch:  18\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 14s 15us/step - loss: 0.2490 - acc: 0.4687 - val_loss: 0.2489 - val_acc: 0.4999\n",
      ". theta fit =  0.16011083\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 14us/step - loss: -0.2490 - acc: 0.5001 - val_loss: -0.2490 - val_acc: 0.4999\n",
      ". theta fit =  0.16377968\n",
      "Epoch:  19\n",
      "Training g\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 12s 14us/step - loss: 0.2490 - acc: 0.4646 - val_loss: 0.2488 - val_acc: 0.4388\n",
      ". theta fit =  0.16377968\n",
      "Training theta\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/1\n",
      "900000/900000 [==============================] - 11s 13us/step - loss: -0.2489 - acc: 0.4376 - val_loss: -0.2489 - val_acc: 0.4388\n",
      ". theta fit =  0.16006933\n"
     ]
    }
   ],
   "source": [
    "myinputs_fit = Input(shape=(1,))\n",
    "x_fit = Dense(128, activation='relu')(myinputs_fit)\n",
    "x2_fit = Dense(128, activation='relu')(x_fit)\n",
    "predictions_fit = Dense(1, activation='sigmoid')(x2_fit)\n",
    "identity = Lambda(lambda x: x + 0)(predictions_fit)\n",
    "\n",
    "model_fit = Model(inputs=myinputs_fit, outputs=identity)\n",
    "model_fit.layers[np.size(model_fit.layers)-1].add_weight(name=\"thetaX\",shape=list(),initializer = keras.initializers.Constant(value = theta_fit_init),trainable=True)\n",
    "model_fit.summary()\n",
    "\n",
    "train_theta = False\n",
    "\n",
    "batch_size = int(len(X_0)/50) #larger batch_size leads to better precision\n",
    "epochs = 20 #but requires more epochs to train\n",
    "\n",
    "def my_loss_wrapper_fit(inputs,mysign = 1):\n",
    "    x  = inputs\n",
    "    x = K.squeeze(x, axis = 1)\n",
    "    x = K.gather(x, np.arange(batch_size))\n",
    "    theta = 0. #starting value\n",
    "    #Getting theta0:\n",
    "    if train_theta == False:\n",
    "        theta0 = model_fit.layers[-1].get_weights() #when not training theta, fetch as np array \n",
    "    else:\n",
    "        theta0 = model_fit.trainable_weights[-1] #when trainingn theta, fetch as tf.Variable\n",
    "        \n",
    "    #creating tensor with same shape as inputs, with val in every entry \n",
    "    theta0_stack = K.ones_like(x,dtype=tf.float32)*theta0 \n",
    "    \n",
    "    #combining and reshaping into correct format:\n",
    "    data = K.stack((x, theta0_stack), axis=-1) \n",
    "   \n",
    "    w = reweight(data) #NN reweight\n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        # Mean Squared Loss\n",
    "        t_loss = mysign*(y_true*(y_true - y_pred)**2+(w)*(1.-y_true)*(y_true - y_pred)**2)\n",
    "        # Categorical Cross-Entropy Loss\n",
    "        \n",
    "        #Clip the prediction value to prevent NaN's and Inf's\n",
    "        '''\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        \n",
    "        t_loss = -mysign*((y_true)*K.log(y_pred) +w*(1-y_true)*K.log(1-y_pred))\n",
    "        '''\n",
    "        return K.mean(t_loss)\n",
    "    return my_loss\n",
    "    \n",
    "for k in range(epochs):    \n",
    "    print(\"Epoch: \",k )\n",
    "    for i in range(len(model_fit.layers)-1):\n",
    "        train_theta = False\n",
    "        model_fit.layers[i].trainable = True\n",
    "        pass\n",
    "    \n",
    "    train_theta = False\n",
    "    model_fit.layers[-1].trainable = False\n",
    "    #model.summary()    \n",
    "    \n",
    "    model_fit.compile(optimizer='adam', loss=my_loss_wrapper_fit(myinputs_fit,1),metrics=['accuracy'])\n",
    "    print(\"Training g\")\n",
    "    model_fit.fit(np.array(X_train), y_train, epochs=1, batch_size=batch_size,validation_data=(np.array(X_test), y_test),verbose=1,callbacks=callbacks)\n",
    "\n",
    "    #Now, fix g and train \\theta.\n",
    "\n",
    "    for i in range(len(model_fit.layers)-1):\n",
    "        model_fit.layers[i].trainable = False\n",
    "        pass    \n",
    "    train_theta = True\n",
    "    model_fit.layers[-1].trainable = True\n",
    "    model_fit.compile(optimizer='adam', loss=my_loss_wrapper_fit(myinputs_fit,-1),metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    print(\"Training theta\")\n",
    "    model_fit.fit(np.array(X_train), y_train, epochs=1, batch_size=batch_size,validation_data=(np.array(X_test), y_test),verbose=1,callbacks=callbacks)    \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fit_vals, label='Model Fit')\n",
    "plt.hlines(0.16, 0, len(fit_vals), label = 'Truth')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(r'$\\theta_{fit}$')\n",
    "plt.legend()\n",
    "plt.title(\"N = {:.0e}, batch_size = {:.0f}, Epochs = {:.0f}\".format(len(X_0), batch_size, epochs*2))\n",
    "#plt.savefig(\":N = {:.0e}, batch_size = {:.0f}, Epochs = {:.0f}\".format(N, batch_size, epochs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
