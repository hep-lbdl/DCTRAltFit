{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCTR Alternative Fitting Algorithm for aLund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:31:04.725679Z",
     "start_time": "2020-06-01T20:31:04.719457Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:31:06.684465Z",
     "start_time": "2020-06-01T20:31:05.155413Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, LambdaCallback\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Model\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:31:06.693399Z",
     "start_time": "2020-06-01T20:31:06.688561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n",
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__) #2.2.4\n",
    "print(tf.__version__) #1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:31:07.576609Z",
     "start_time": "2020-06-01T20:31:07.566881Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize pT and center (y, phi)\n",
    "def normalize(x):\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:31:07.971994Z",
     "start_time": "2020-06-01T20:31:07.964130Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    for x in X:\n",
    "        normalize(x)\n",
    "    \n",
    "    # Remap PIDs to unique values in range [0,1]\n",
    "    remap_pids(X, pid_i=3)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:31:08.832142Z",
     "start_time": "2020-06-01T20:31:08.827734Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to downloaded data from Zenodo\n",
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:31:09.259033Z",
     "start_time": "2020-06-01T20:31:09.252699Z"
    }
   },
   "outputs": [],
   "source": [
    "default_dataset = np.load(data_dir + 'test1D_default.npz')\n",
    "unknown_dataset = np.load(data_dir + 'test1D_aLund.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:33:34.500146Z",
     "start_time": "2020-06-01T20:31:09.719115Z"
    }
   },
   "outputs": [],
   "source": [
    "X_default = preprocess_data(default_dataset['jet'][:,:,:4])\n",
    "X_unknown = preprocess_data(unknown_dataset['jet'][:,:,:4])\n",
    "\n",
    "Y_default = np.zeros_like(X_default[:,0,0])\n",
    "Y_unknown = np.ones_like(X_unknown[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:33:44.058688Z",
     "start_time": "2020-06-01T20:33:43.021577Z"
    }
   },
   "outputs": [],
   "source": [
    "X_fit = np.concatenate((X_default, X_unknown), axis = 0)\n",
    "\n",
    "Y_fit = np.concatenate((Y_default, Y_unknown), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:33:44.909917Z",
     "start_time": "2020-06-01T20:33:44.062294Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = data_split(X_fit, Y_fit, test=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:33:46.137584Z",
     "start_time": "2020-06-01T20:33:44.913567Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# network architecture parameters\n",
    "Phi_sizes = (100,100, 128)\n",
    "F_sizes = (100,100, 100)\n",
    "\n",
    "dctr = PFN(input_dim=7, \n",
    "           Phi_sizes=Phi_sizes, F_sizes=F_sizes,\n",
    "           summary=False)\n",
    "\n",
    "# load model from saved file\n",
    "# model trained in original alphaS notebook\n",
    "dctr.model.load_weights('./saved_models/DCTR_ee_dijets_1D_aLund.h5') #ORIGINAL DCTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining reweighting functions\n",
    "\n",
    "$w(x_{T,i},\\theta)=((f(x_{T,i},\\theta)/(1-f(x_{T,i},\\theta)))$\n",
    "\n",
    "Takes observable from simulation ${\\bf \\theta_0}$ and weights it to observable from data (target) ${\\bf \\theta_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:33:46.147199Z",
     "start_time": "2020-06-01T20:33:46.141467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining reweighting functions\n",
    "\n",
    "def reweight(d): #from NN (DCTR)\n",
    "    f = dctr.model(d) # Use dctr.model.predict_on_batch(d) when using outside training\n",
    "    weights = (f[:,1])/(f[:,0])\n",
    "    weights = K.expand_dims(weights, axis = 1)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T20:33:46.290726Z",
     "start_time": "2020-06-01T20:33:46.150944Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = PFN(input_dim=4, \n",
    "            Phi_sizes=Phi_sizes, F_sizes=F_sizes, \n",
    "            output_dim = 1, output_act = 'sigmoid',\n",
    "            summary=False)\n",
    "myinputs = model.inputs[0]\n",
    "batch_size = 1000\n",
    "\n",
    "earlystopping = EarlyStopping(patience = 5,\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "def my_loss_wrapper(inputs, val=0):\n",
    "    x  = inputs #x.shape = (?,?,4)\n",
    "    #Reshaping to correct format\n",
    "    x = tf.gather(x, np.arange(batch_size))\n",
    "    x = tf.gather(x, np.arange(51), axis = 1) # Axis corressponds to (max) number of particles in each event\n",
    "\n",
    "    theta_prime = [0.1365, val, 0.217] # [alphaS, aLund, probStuUD]\n",
    "    \n",
    "    # zip theta_prime to each input particle (but not to the padded rows)\n",
    "    concat_input_and_params = tf.where(K.abs(x[...,0])>0, #checks if pT != 0, which means we have a particle\n",
    "                                   K.ones_like(x[...,0]),\n",
    "                                   K.zeros_like(x[...,0]))\n",
    "    \n",
    "    concat_input_and_params = theta_prime*K.stack([concat_input_and_params, \n",
    "                                                   concat_input_and_params, \n",
    "                                                   concat_input_and_params], \n",
    "                                                  axis = -1)\n",
    "    \n",
    "    data = K.concatenate([x, concat_input_and_params], -1)\n",
    "    # print(data.shape) # = (batch_size, 51, 7), correct format to pass to DCTR\n",
    "    w = reweight(data) # NN reweight\n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        # Mean-Squared Loss:\n",
    "        #t_loss = (y_true)*(y_true - y_pred)**2 +(w)*(1-y_true)*(y_true - y_pred)**2\n",
    "        \n",
    "        # Categorical Cross-Entropy Loss\n",
    "        \n",
    "        #Clip the prediction value to prevent NaN's and Inf's\n",
    "        \n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        \n",
    "        t_loss = -((y_true)*K.log(y_pred) +w*(1-y_true)*K.log(1-y_pred))\n",
    "        \n",
    "        return K.mean(t_loss)\n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T23:39:58.418558Z",
     "start_time": "2020-06-01T20:33:46.294489Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainnig theta = : 0.5\n",
      "WARNING:tensorflow:From <ipython-input-14-ec90c485163b>:23: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/asuresh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/50\n",
      "900000/900000 [==============================] - 133s 147us/step - loss: 0.6986 - acc: 0.5072 - val_loss: 0.6929 - val_acc: 0.5099\n",
      "Epoch 2/50\n",
      "900000/900000 [==============================] - 130s 145us/step - loss: 0.6930 - acc: 0.5089 - val_loss: 0.6927 - val_acc: 0.5094\n",
      "Epoch 3/50\n",
      "900000/900000 [==============================] - 129s 143us/step - loss: 0.6926 - acc: 0.5104 - val_loss: 0.6928 - val_acc: 0.5084\n",
      "Epoch 4/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6924 - acc: 0.5106 - val_loss: 0.6923 - val_acc: 0.5111\n",
      "Epoch 5/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6924 - acc: 0.5109 - val_loss: 0.6922 - val_acc: 0.5107\n",
      "Epoch 6/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6923 - acc: 0.5106 - val_loss: 0.6922 - val_acc: 0.5112\n",
      "Epoch 7/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6923 - acc: 0.5109 - val_loss: 0.6922 - val_acc: 0.5113\n",
      "Epoch 8/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6923 - acc: 0.5112 - val_loss: 0.6923 - val_acc: 0.5102\n",
      "Epoch 9/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6923 - acc: 0.5114 - val_loss: 0.6922 - val_acc: 0.5113\n",
      "Epoch 10/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6922 - acc: 0.5112 - val_loss: 0.6923 - val_acc: 0.5105\n",
      "Epoch 11/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6922 - acc: 0.5115 - val_loss: 0.6923 - val_acc: 0.5106\n",
      "Epoch 12/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6922 - acc: 0.5111 - val_loss: 0.6922 - val_acc: 0.5118\n",
      "Epoch 13/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6921 - acc: 0.5114 - val_loss: 0.6921 - val_acc: 0.5117\n",
      "Epoch 14/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6921 - acc: 0.5117 - val_loss: 0.6921 - val_acc: 0.5119\n",
      "Epoch 15/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6921 - acc: 0.5121 - val_loss: 0.6929 - val_acc: 0.5097\n",
      "Epoch 16/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6921 - acc: 0.5124 - val_loss: 0.6921 - val_acc: 0.5120\n",
      "Epoch 17/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6920 - acc: 0.5124 - val_loss: 0.6922 - val_acc: 0.5111\n",
      "Epoch 18/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6921 - acc: 0.5118 - val_loss: 0.6922 - val_acc: 0.5122\n",
      "Epoch 19/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6920 - acc: 0.5120 - val_loss: 0.6921 - val_acc: 0.5120\n",
      "Epoch 20/50\n",
      "900000/900000 [==============================] - 129s 143us/step - loss: 0.6920 - acc: 0.5123 - val_loss: 0.6922 - val_acc: 0.5118\n",
      "Epoch 21/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6920 - acc: 0.5125 - val_loss: 0.6922 - val_acc: 0.5111\n",
      "trainnig theta = : 0.55\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6940 - acc: 0.5121 - val_loss: 0.6940 - val_acc: 0.5121\n",
      "Epoch 2/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6940 - acc: 0.5124 - val_loss: 0.6941 - val_acc: 0.5111\n",
      "Epoch 3/50\n",
      "900000/900000 [==============================] - 125s 138us/step - loss: 0.6939 - acc: 0.5124 - val_loss: 0.6940 - val_acc: 0.5124\n",
      "Epoch 4/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6939 - acc: 0.5130 - val_loss: 0.6940 - val_acc: 0.5121\n",
      "Epoch 6/50\n",
      "900000/900000 [==============================] - 125s 138us/step - loss: 0.6939 - acc: 0.5128 - val_loss: 0.6942 - val_acc: 0.5119\n",
      "Epoch 7/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6939 - acc: 0.5128 - val_loss: 0.6941 - val_acc: 0.5117\n",
      "Epoch 8/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6938 - acc: 0.5133 - val_loss: 0.6942 - val_acc: 0.5115\n",
      "Epoch 9/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6938 - acc: 0.5127 - val_loss: 0.6941 - val_acc: 0.5117\n",
      "Epoch 10/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6938 - acc: 0.5133 - val_loss: 0.6941 - val_acc: 0.5119\n",
      "trainnig theta = : 0.6\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/50\n",
      "900000/900000 [==============================] - 129s 143us/step - loss: 0.6946 - acc: 0.5121 - val_loss: 0.6947 - val_acc: 0.5117\n",
      "Epoch 2/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6946 - acc: 0.5126 - val_loss: 0.6947 - val_acc: 0.5115\n",
      "Epoch 3/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6945 - acc: 0.5130 - val_loss: 0.6947 - val_acc: 0.5124\n",
      "Epoch 4/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6945 - acc: 0.5127 - val_loss: 0.6948 - val_acc: 0.5122\n",
      "Epoch 5/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6945 - acc: 0.5130 - val_loss: 0.6948 - val_acc: 0.5113\n",
      "Epoch 6/50\n",
      "900000/900000 [==============================] - 125s 138us/step - loss: 0.6945 - acc: 0.5132 - val_loss: 0.6947 - val_acc: 0.5121\n",
      "Epoch 7/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6945 - acc: 0.5131 - val_loss: 0.6948 - val_acc: 0.5120\n",
      "Epoch 8/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6945 - acc: 0.5134 - val_loss: 0.6947 - val_acc: 0.5124\n",
      "Epoch 9/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6944 - acc: 0.5138 - val_loss: 0.6947 - val_acc: 0.5125\n",
      "Epoch 10/50\n",
      "900000/900000 [==============================] - 125s 138us/step - loss: 0.6944 - acc: 0.5136 - val_loss: 0.6949 - val_acc: 0.5119\n",
      "Epoch 11/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6944 - acc: 0.5138 - val_loss: 0.6949 - val_acc: 0.5122\n",
      "Epoch 12/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6944 - acc: 0.5136 - val_loss: 0.6948 - val_acc: 0.5126\n",
      "Epoch 13/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6944 - acc: 0.5137 - val_loss: 0.6949 - val_acc: 0.5124\n",
      "Epoch 14/50\n",
      "900000/900000 [==============================] - 125s 138us/step - loss: 0.6943 - acc: 0.5143 - val_loss: 0.6947 - val_acc: 0.5122\n",
      "trainnig theta = : 0.65\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/50\n",
      "900000/900000 [==============================] - 132s 147us/step - loss: 0.6930 - acc: 0.5134 - val_loss: 0.6933 - val_acc: 0.5127\n",
      "Epoch 2/50\n",
      "900000/900000 [==============================] - 130s 144us/step - loss: 0.6930 - acc: 0.5137 - val_loss: 0.6934 - val_acc: 0.5118\n",
      "Epoch 3/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6930 - acc: 0.5135 - val_loss: 0.6934 - val_acc: 0.5115\n",
      "Epoch 4/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6930 - acc: 0.5138 - val_loss: 0.6936 - val_acc: 0.5105\n",
      "Epoch 5/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6930 - acc: 0.5142 - val_loss: 0.6934 - val_acc: 0.5122\n",
      "Epoch 6/50\n",
      "900000/900000 [==============================] - 126s 140us/step - loss: 0.6929 - acc: 0.5141 - val_loss: 0.6934 - val_acc: 0.5114\n",
      "trainnig theta = : 0.7\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900000/900000 [==============================] - 132s 146us/step - loss: 0.6907 - acc: 0.5132 - val_loss: 0.6909 - val_acc: 0.5114\n",
      "Epoch 2/50\n",
      "900000/900000 [==============================] - 129s 143us/step - loss: 0.6906 - acc: 0.5136 - val_loss: 0.6909 - val_acc: 0.5115\n",
      "Epoch 3/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6906 - acc: 0.5135 - val_loss: 0.6909 - val_acc: 0.5108\n",
      "Epoch 4/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6906 - acc: 0.5128 - val_loss: 0.6909 - val_acc: 0.5086\n",
      "Epoch 5/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6905 - acc: 0.5143 - val_loss: 0.6911 - val_acc: 0.5100\n",
      "Epoch 6/50\n",
      "900000/900000 [==============================] - 126s 140us/step - loss: 0.6905 - acc: 0.5131 - val_loss: 0.6910 - val_acc: 0.5092\n",
      "Epoch 7/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6905 - acc: 0.5140 - val_loss: 0.6909 - val_acc: 0.5109\n",
      "trainnig theta = : 0.75\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/50\n",
      "900000/900000 [==============================] - 130s 145us/step - loss: 0.6887 - acc: 0.5110 - val_loss: 0.6891 - val_acc: 0.5068\n",
      "Epoch 2/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6886 - acc: 0.5113 - val_loss: 0.6890 - val_acc: 0.5061\n",
      "Epoch 3/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6886 - acc: 0.5107 - val_loss: 0.6891 - val_acc: 0.5053\n",
      "Epoch 4/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6886 - acc: 0.5115 - val_loss: 0.6890 - val_acc: 0.5043\n",
      "Epoch 5/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6886 - acc: 0.5112 - val_loss: 0.6890 - val_acc: 0.5064\n",
      "Epoch 6/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6885 - acc: 0.5117 - val_loss: 0.6890 - val_acc: 0.5047\n",
      "Epoch 7/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6885 - acc: 0.5123 - val_loss: 0.6891 - val_acc: 0.5053\n",
      "trainnig theta = : 0.8\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6869 - acc: 0.5090 - val_loss: 0.6873 - val_acc: 0.5059\n",
      "Epoch 2/50\n",
      "900000/900000 [==============================] - 125s 139us/step - loss: 0.6869 - acc: 0.5094 - val_loss: 0.6873 - val_acc: 0.5027\n",
      "Epoch 3/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6868 - acc: 0.5101 - val_loss: 0.6872 - val_acc: 0.5041\n",
      "Epoch 4/50\n",
      "900000/900000 [==============================] - 125s 138us/step - loss: 0.6868 - acc: 0.5094 - val_loss: 0.6873 - val_acc: 0.5027\n",
      "Epoch 5/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6868 - acc: 0.5098 - val_loss: 0.6874 - val_acc: 0.5041\n",
      "Epoch 6/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6868 - acc: 0.5095 - val_loss: 0.6873 - val_acc: 0.5027\n",
      "Epoch 7/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6867 - acc: 0.5096 - val_loss: 0.6874 - val_acc: 0.5036\n",
      "Epoch 8/50\n",
      "900000/900000 [==============================] - 124s 138us/step - loss: 0.6866 - acc: 0.5109 - val_loss: 0.6874 - val_acc: 0.5047\n",
      "trainnig theta = : 0.8500000000000001\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/50\n",
      "900000/900000 [==============================] - 131s 146us/step - loss: 0.6859 - acc: 0.5085 - val_loss: 0.6864 - val_acc: 0.5011\n",
      "Epoch 2/50\n",
      "900000/900000 [==============================] - 129s 144us/step - loss: 0.6859 - acc: 0.5088 - val_loss: 0.6867 - val_acc: 0.5012\n",
      "Epoch 3/50\n",
      "900000/900000 [==============================] - 130s 144us/step - loss: 0.6858 - acc: 0.5087 - val_loss: 0.6863 - val_acc: 0.5026\n",
      "Epoch 4/50\n",
      "900000/900000 [==============================] - 129s 144us/step - loss: 0.6858 - acc: 0.5094 - val_loss: 0.6864 - val_acc: 0.5034\n",
      "Epoch 5/50\n",
      "900000/900000 [==============================] - 128s 142us/step - loss: 0.6857 - acc: 0.5099 - val_loss: 0.6865 - val_acc: 0.5021\n",
      "Epoch 6/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6857 - acc: 0.5103 - val_loss: 0.6865 - val_acc: 0.5029\n",
      "Epoch 7/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6856 - acc: 0.5114 - val_loss: 0.6866 - val_acc: 0.5025\n",
      "Epoch 8/50\n",
      "900000/900000 [==============================] - 127s 142us/step - loss: 0.6856 - acc: 0.5105 - val_loss: 0.6865 - val_acc: 0.5014\n",
      "trainnig theta = : 0.9\n",
      "Train on 900000 samples, validate on 900000 samples\n",
      "Epoch 1/50\n",
      "900000/900000 [==============================] - 130s 144us/step - loss: 0.6854 - acc: 0.5087 - val_loss: 0.6861 - val_acc: 0.5015\n",
      "Epoch 2/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6853 - acc: 0.5095 - val_loss: 0.6861 - val_acc: 0.5014\n",
      "Epoch 3/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6853 - acc: 0.5093 - val_loss: 0.6863 - val_acc: 0.5040\n",
      "Epoch 4/50\n",
      "900000/900000 [==============================] - 126s 140us/step - loss: 0.6852 - acc: 0.5094 - val_loss: 0.6866 - val_acc: 0.5043\n",
      "Epoch 5/50\n",
      "900000/900000 [==============================] - 127s 141us/step - loss: 0.6852 - acc: 0.5097 - val_loss: 0.6862 - val_acc: 0.5028\n",
      "Epoch 6/50\n",
      "900000/900000 [==============================] - 129s 143us/step - loss: 0.6852 - acc: 0.5100 - val_loss: 0.6863 - val_acc: 0.5006\n",
      "Epoch 7/50\n",
      "900000/900000 [==============================] - 129s 143us/step - loss: 0.6851 - acc: 0.5107 - val_loss: 0.6862 - val_acc: 0.5025\n",
      "[0.691980543533961, 0.6937870417700873, 0.6943309132920371, 0.6929433571630054, 0.6904906568924586, 0.6884784617026647, 0.686649022632175, 0.6855657130479813, 0.6850964664088355]\n"
     ]
    }
   ],
   "source": [
    "thetas = np.linspace(0.50, 0.90, 9)  #iterating across possible aLund values\n",
    "lvals = []\n",
    "vlvals = []\n",
    "\n",
    "for theta in thetas:\n",
    "    print(\"trainnig theta = :\", theta)\n",
    "    model.model.compile(optimizer='adam',\n",
    "                        loss=my_loss_wrapper(myinputs, theta),\n",
    "                        metrics=['accuracy'])\n",
    "    history = model.fit(X_train,\n",
    "                        Y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        verbose=1,\n",
    "                        callbacks=[earlystopping])\n",
    "    lvals += [np.min(history.history['loss'])]\n",
    "    vlvals += [np.min(history.history['val_loss'])]\n",
    "    print\n",
    "    pass\n",
    "print(lvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T23:49:40.848981Z",
     "start_time": "2020-06-01T23:49:40.587418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thetas,lvals, label = 'lvals')\n",
    "plt.plot(thetas,vlvals, label = 'vlvals')\n",
    "plt.vlines(0.80, ymin = np.min(lvals), ymax = np.max(lvals), label = 'Truth')\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title(\"aLund vs. Loss (g FULLY TRAINED)\")\n",
    "plt.savefig(\"aLund vs. Loss (g FULLY TRAINED).png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T03:26:06.393777Z",
     "start_time": "2020-05-31T03:26:05.603Z"
    }
   },
   "outputs": [],
   "source": [
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(\". theta fit = \",model_fit.layers[-1].get_weights()[-1]))\n",
    "theta_fit_init = 0.68\n",
    "fit_vals = [theta_fit_init]\n",
    "append_fit_value = LambdaCallback(on_epoch_end=lambda batch, logs: \n",
    "                                               fit_vals.append(model_fit.layers[-1].get_weights()[0]))\n",
    "\n",
    "callbacks = [print_weights, append_fit_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T03:26:06.395012Z",
     "start_time": "2020-05-31T03:26:05.604Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PFN_model = PFN(input_dim=4, \n",
    "            Phi_sizes=Phi_sizes, F_sizes=F_sizes, \n",
    "            output_dim = 1, output_act = 'sigmoid',\n",
    "            summary=False)\n",
    "myinputs_fit = PFN_model.inputs[0]\n",
    "\n",
    "identity = Lambda(lambda x: x + 0)(PFN_model.output)\n",
    "\n",
    "model_fit = Model(inputs=myinputs_fit, outputs=identity)\n",
    "model_fit.layers[np.size(model_fit.layers)-1].add_weight(name=\"thetaX\",shape=list(),\n",
    "                                                         initializer = keras.initializers.Constant(value = theta_fit_init),\n",
    "                                                         trainable=True)\n",
    "model_fit.summary()\n",
    "\n",
    "train_theta = False\n",
    "\n",
    "batch_size = 1000\n",
    "lr = 5e-7 #smaller learning rate yields better precision\n",
    "epochs = 60 #but requires more epochs to train\n",
    "optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "def my_loss_wrapper_fit(inputs,mysign = 1):\n",
    "    x  = inputs #x.shape = (?,?,4)\n",
    "    # Reshaping to correct format\n",
    "    x = tf.gather(x, np.arange(batch_size))\n",
    "    x = tf.gather(x, np.arange(51), axis = 1) # Axis corressponds to (max) number of particles in each event\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Getting theta0:\n",
    "    if train_theta == False:\n",
    "        theta0 = model_fit.layers[-1].get_weights()[0] #when not training theta, fetch as np array\n",
    "        \n",
    "    else:\n",
    "        theta0 = model_fit.trainable_weights[-1] #when training theta, fetch as tf.Variable\n",
    "        \n",
    "    theta_prime = [0.1365, theta0, 0.217]\n",
    "    \n",
    "    # Add MC params to each input particle (but not to the padded rows)\n",
    "    concat_input_and_params = tf.where(K.abs(x[...,0])>0,\n",
    "                                   K.ones_like(x[...,0]),\n",
    "                                   K.zeros_like(x[...,0]))\n",
    "    \n",
    "    concat_input_and_params = theta_prime*K.stack([concat_input_and_params, concat_input_and_params, concat_input_and_params], axis = -1)\n",
    "    \n",
    "    data = K.concatenate([x, concat_input_and_params], -1)\n",
    "    # print(data.shape) # = (batch_size, 51, 7), correct format to pass to DCTR\n",
    "    w = reweight(data) # NN reweight\n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        # Mean Squared Loss\n",
    "        t_loss = mysign*(y_true*(y_true - y_pred)**2+(w)*(1.-y_true)*(y_true - y_pred)**2)\n",
    "        # Categorical Cross-Entropy Loss\n",
    "        \n",
    "        #Clip the prediction value to prevent NaN's and Inf's\n",
    "        '''\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        \n",
    "        t_loss = -mysign*((y_true)*K.log(y_pred) +w*(1-y_true)*K.log(1-y_pred))\n",
    "        '''\n",
    "        return K.mean(t_loss)\n",
    "    return my_loss\n",
    "    \n",
    "for k in range(epochs):    \n",
    "    print(\"Epoch: \",k )\n",
    "    for i in range(len(model_fit.layers)-1):\n",
    "        train_theta = False\n",
    "        model_fit.layers[i].trainable = True\n",
    "        pass\n",
    "    train_theta = False\n",
    "    model_fit.layers[-1].trainable = False\n",
    "    #model.summary()    \n",
    "    \n",
    "    model_fit.compile(optimizer='adam', loss=my_loss_wrapper_fit(myinputs_fit,1),metrics=['accuracy'])\n",
    "    print(\"Training g\")\n",
    "    model_fit.fit(X_train, Y_train, epochs=1, batch_size=batch_size,validation_data=(X_test, Y_test),verbose=1,callbacks=callbacks)\n",
    "\n",
    "    #Now, fix g and train \\theta.\n",
    "\n",
    "    for i in range(len(model_fit.layers)-1):\n",
    "        model_fit.layers[i].trainable = False\n",
    "        pass    \n",
    "    train_theta = True\n",
    "    model_fit.layers[-1].trainable = True\n",
    "    \n",
    "    model_fit.compile(optimizer=optimizer, loss=my_loss_wrapper_fit(myinputs_fit,-1),metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    print(\"Training theta\")\n",
    "    model_fit.fit(X_train, Y_train, epochs=1, batch_size=batch_size,validation_data=(X_test, Y_test),verbose=1,callbacks=callbacks)    \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T03:26:06.396232Z",
     "start_time": "2020-05-31T03:26:05.606Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(fit_vals, label='Model Fit')\n",
    "plt.hlines(0.80, 0, len(fit_vals), label = 'Truth')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(r'$\\theta_{fit}$')\n",
    "plt.legend()\n",
    "plt.title(\"aLund Fit \\nN = {:.0e}, learning_rate = {:.0e}\".format(len(X_default), lr))\n",
    "plt.savefig(\"aLund Fit\\nN = {:.0e}, learning_rate = {:.0e}.png\".format(len(X_default), 5e-7))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
